pip install torch torchvision diffusers tqdm


CheXpert-v1.0-small/
├── train/
│   ├── positive_class_1/
│   ├── positive_class_2/
│   └── no_findings/
└── valid/
    ├── positive_class_1/
    ├── positive_class_2/
    └── no_findings/


import os
from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from PIL import Image

# Define transformations for input images
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]
])

# Load the dataset
data_dir = "/path/to/CheXpert-v1.0-small/train"
dataset = ImageFolder(root=data_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)



import torch
from diffusers import DDPMScheduler, UNet2DModel, DDPMPipeline

device = "cuda" if torch.cuda.is_available() else "cpu"

# Define the UNet model
model = UNet2DModel(
    sample_size=256,  # Image size
    in_channels=1,    # Grayscale images
    out_channels=1,
    layers_per_block=2,
    block_out_channels=(64, 128, 256, 512),
    down_block_types=("DownBlock2D",) * 4,
    up_block_types=("UpBlock2D",) * 4,
).to(device)

# Initialize the scheduler for the diffusion process
scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule="linear")

# Create a pipeline for image generation
pipeline = DDPMPipeline(unet=model, scheduler=scheduler)



from tqdm import tqdm

optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
epochs = 5

model.train()
for epoch in range(epochs):
    for batch in tqdm(dataloader):
        images, _ = batch
        images = images.to(device)
        
        # Sample random noise
        noise = torch.randn_like(images).to(device)
        timesteps = torch.randint(0, scheduler.num_train_timesteps, (images.shape[0],), device=device).long()
        
        # Add noise to images based on the timestep
        noisy_images = scheduler.add_noise(images, noise, timesteps)
        
        # Predict the noise using the model
        noise_pred = model(noisy_images, timesteps).sample
        
        # Compute the loss (mean squared error)
        loss = torch.nn.functional.mse_loss(noise_pred, noise)
        
        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}")



import shutil
from tqdm import tqdm

# Define where to save generated images
generated_data_dir = "/path/to/generated-CheXpert"

# Function to create folder structure
def create_folder_structure(original_dir, generated_dir):
    if not os.path.exists(generated_dir):
        shutil.copytree(original_dir, generated_dir, dirs_exist_ok=True)
        # Remove original images in the generated folder
        for root, dirs, files in os.walk(generated_dir):
            for file in files:
                os.remove(os.path.join(root, file))

# Create the folder structure
create_folder_structure(data_dir, generated_data_dir)

# Generate and save images
model.eval()
for batch, (images, labels) in tqdm(enumerate(dataloader), total=len(dataloader)):
    with torch.no_grad():
        # Generate synthetic images
        generated_images = pipeline(num_inference_steps=100, batch_size=images.size(0)).images
        generated_images = (generated_images * 0.5 + 0.5).clip(0, 1)  # De-normalize to [0, 1]

        for i, img in enumerate(generated_images):
            # Convert tensor to PIL image
            img = transforms.ToPILImage()(img.squeeze(0))
            
            # Get the original image path and replicate it
            original_img_path, _ = dataset.samples[batch * images.size(0) + i]
            sub_path = os.path.relpath(original_img_path, data_dir)
            save_path = os.path.join(generated_data_dir, sub_path)
            
            # Ensure the directory exists
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            img.save(save_path)





pip install torch torchvision diffusers
import torch
from diffusers import DDPMPipeline

# Check if CUDA is available
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load a pre-trained DDPM pipeline from Hugging Face
model_id = "google/ddpm-cifar10-32"  # Example pre-trained model
pipeline = DDPMPipeline.from_pretrained(model_id)
pipeline.to(device)

# Update the model to handle grayscale images if needed
pipeline.unet.config.in_channels = 1
pipeline.unet.to(device)


import os
from PIL import Image
from tqdm import tqdm
from torchvision import transforms

# Set paths
data_dir = "/path/to/CheXpert-v1.0-small/train"
generated_data_dir = "/path/to/generated-CheXpert"

# Create folder structure similar to original dataset
def create_folder_structure(original_dir, generated_dir):
    if not os.path.exists(generated_dir):
        os.makedirs(generated_dir, exist_ok=True)
        for root, dirs, _ in os.walk(original_dir):
            for dir_name in dirs:
                os.makedirs(os.path.join(generated_dir, os.path.relpath(root, original_dir), dir_name), exist_ok=True)

# Create the folder structure for generated images
create_folder_structure(data_dir, generated_data_dir)

# Image transformation
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# Generate synthetic images and save them in the corresponding folders
pipeline.eval()
for root, dirs, files in tqdm(os.walk(data_dir)):
    for file in files:
        if file.endswith('.jpg') or file.endswith('.png'):
            original_img_path = os.path.join(root, file)
            
            # Generate new image using the pre-trained model
            with torch.no_grad():
                generated_image = pipeline(num_inference_steps=50).images[0]  # Generates a single image

            # Save the generated image in the corresponding folder
            sub_path = os.path.relpath(original_img_path, data_dir)
            save_path = os.path.join(generated_data_dir, sub_path)
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            # Convert tensor to PIL image and save
            generated_image.save(save_path)

print(f"Generated images saved to: {generated_data_dir}")


